
@article{cho_learning_2014,
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1406.1078},
	abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	urldate = {2021-08-08},
	journal = {arXiv:1406.1078 [cs, stat]},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {arXiv: 1406.1078},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/philmoremorrison/Zotero/storage/SESNABYT/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-.pdf:application/pdf;arXiv.org Snapshot:/Users/philmoremorrison/Zotero/storage/QUZ3S5NI/1406.html:text/html},
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	number = {8},
	journal = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	year = {1997},
	note = {Publisher: MIT Press},
	pages = {1735--1780},
	file = {2604.pdf:/Users/philmoremorrison/Zotero/storage/8235GZZB/2604.pdf:application/pdf},
}

@article{zhou_c-lstm_2015,
	title = {A {C}-{LSTM} {Neural} {Network} for {Text} {Classification}},
	url = {http://arxiv.org/abs/1511.08630},
	abstract = {Neural network models have been demonstrated to be capable of achieving remarkable performance in sentence and document modeling. Convolutional neural network (CNN) and recurrent neural network (RNN) are two mainstream architectures for such modeling tasks, which adopt totally different ways of understanding natural languages. In this work, we combine the strengths of both architectures and propose a novel and uniﬁed model called C-LSTM for sentence representation and text classiﬁcation. C-LSTM utilizes CNN to extract a sequence of higher-level phrase representations, and are fed into a long short-term memory recurrent neural network (LSTM) to obtain the sentence representation. C-LSTM is able to capture both local features of phrases as well as global and temporal sentence semantics. We evaluate the proposed architecture on sentiment classiﬁcation and question classiﬁcation tasks. The experimental results show that the C-LSTM outperforms both CNN and LSTM and can achieve excellent performance on these tasks.},
	language = {en},
	urldate = {2021-08-08},
	journal = {arXiv:1511.08630 [cs]},
	author = {Zhou, Chunting and Sun, Chonglin and Liu, Zhiyuan and Lau, Francis C. M.},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.08630},
	keywords = {Computer Science - Computation and Language},
	file = {Zhou et al. - 2015 - A C-LSTM Neural Network for Text Classification.pdf:/Users/philmoremorrison/Zotero/storage/ERBK8GJS/Zhou et al. - 2015 - A C-LSTM Neural Network for Text Classification.pdf:application/pdf},
}

@misc{phi_illustrated_2020,
	title = {Illustrated {Guide} to {LSTM}’s and {GRU}’s: {A} step by step explanation},
	shorttitle = {Illustrated {Guide} to {LSTM}’s and {GRU}’s},
	url = {https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21},
	abstract = {Hi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I’m Michael, and I’m a Machine…},
	language = {en},
	journal = {Medium},
	author = {Phi, Michael},
	month = jun,
	year = {2020},
	file = {Snapshot:/Users/philmoremorrison/Zotero/storage/G39T45TP/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21.html:text/html},
}

@inproceedings{mavrogiannis_socially_2017,
	address = {Vancouver, BC},
	title = {Socially competent navigation planning by deep learning of multi-agent path topologies},
	isbn = {978-1-5386-2682-5},
	url = {http://ieeexplore.ieee.org/document/8206601/},
	doi = {10.1109/IROS.2017.8206601},
	abstract = {We present a novel, data-driven framework for planning socially competent robot behaviors in crowded environments. The core of our approach is a topological model of collective navigation behaviors, based on braid groups. This model constitutes the basis for the design of a human-inspired probabilistic inference mechanism that predicts the topology of multiple agents’ future trajectories, given observations of the context. We derive an approximation of this mechanism by employing a neural network learning architecture on synthetic data of collective navigation behaviors. Our planner makes use of this mechanism as a tool for interpreting the context and understanding what future behaviors are in compliance with it. The planning agent makes use of this understanding to determine a personal action that contributes to the context in the most clear way possible, while ensuring progress to its destination. Our simulations provide evidence that our planning framework results in socially competent navigation behaviors not only for the planning agent, but also for interacting naive agents. Performance beneﬁts include (1) early conﬂict resolutions and (2) faster uncertainty decrease for the other agents in the scene.},
	language = {en},
	urldate = {2021-08-09},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Mavrogiannis, Christoforos I. and Blukis, Valts and Knepper, Ross A.},
	month = sep,
	year = {2017},
	pages = {6817--6824},
	file = {Mavrogiannis et al. - 2017 - Socially competent navigation planning by deep lea.pdf:/Users/philmoremorrison/Zotero/storage/A87WLXY3/Mavrogiannis et al. - 2017 - Socially competent navigation planning by deep lea.pdf:application/pdf},
}

@article{nakayama_zero-resource_2017,
	title = {Zero-resource machine translation by multimodal encoder–decoder network with multimedia pivot},
	volume = {31},
	issn = {0922-6567, 1573-0573},
	url = {http://link.springer.com/10.1007/s10590-017-9197-z},
	doi = {10.1007/s10590-017-9197-z},
	abstract = {We propose an approach to build a neural mach no supervised resources (i.e., no parallel corpora) using resentation over texts and images. Based on the assumpti often likely to be described with other multimedia infor what related to the content, we try to indirectly estimat languages. Using multimedia as the "pivot", we project mon hidden space where samples belonging to similar sem close to each other, whatever the observed space of each agnostic representation is the key to bridging the gap b Putting a decoder on top of it, our network can flexibly dra modality. Notably, in the testing phase, we need only sourc for translation. In experiments, we tested our method on t it can achieve reasonable translation performance. We com eral possible implementations and found that an end-to-en optimized both rank loss in multimodal encoders and cro performed the best.},
	language = {en},
	number = {1-2},
	urldate = {2021-08-09},
	journal = {Machine Translation},
	author = {Nakayama, Hideki and Nishida, Noriki},
	month = jun,
	year = {2017},
	pages = {49--64},
	file = {Nakayama and Nishida - 2017 - Zero-resource machine translation by multimodal en.pdf:/Users/philmoremorrison/Zotero/storage/HQIB5YJI/Nakayama and Nishida - 2017 - Zero-resource machine translation by multimodal en.pdf:application/pdf},
}

@article{huang_detecting_2019,
	title = {Detecting {Anomalous} {Vessel} {Dynamics} with {Functional} {Data} {Analysis}},
	volume = {91},
	issn = {0749-0208},
	url = {https://bioone.org/journals/journal-of-coastal-research/volume-91/issue-sp1/SI91-082.1/Detecting-Anomalous-Vessel-Dynamics-with-Functional-Data-Analysis/10.2112/SI91-082.1.full},
	doi = {10.2112/SI91-082.1},
	language = {en},
	number = {sp1},
	urldate = {2021-08-09},
	journal = {Journal of Coastal Research},
	author = {Huang, He and Qiu, Kaiyue and Jeong, Myeong-Hun and Jeon, Seung Bae and Lee, Woo Pyeong},
	month = aug,
	year = {2019},
	pages = {406},
	file = {Huang et al. - 2019 - Detecting Anomalous Vessel Dynamics with Functiona.pdf:/Users/philmoremorrison/Zotero/storage/HAK4CTAB/Huang et al. - 2019 - Detecting Anomalous Vessel Dynamics with Functiona.pdf:application/pdf},
}

@article{dasgupta_neural_2018,
	title = {A neural data structure for novelty detection},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1814448115},
	doi = {10.1073/pnas.1814448115},
	abstract = {Novelty detection is a fundamental biological problem that organisms must solve to determine whether a given stimulus departs from those previously experienced. In computer science, this problem is solved efficiently using a data structure called a Bloom filter. We found that the fruit fly olfactory circuit evolved a variant of a Bloom filter to assess the novelty of odors. Compared with a traditional Bloom filter, the fly adjusts novelty responses based on two additional features: the similarity of an odor to previously experienced odors and the time elapsed since the odor was last experienced. We elaborate and validate a framework to predict novelty responses of fruit flies to given pairs of odors. We also translate insights from the fly circuit to develop a class of distance- and time-sensitive Bloom filters that outperform prior filters when evaluated on several biological and computational datasets. Overall, our work illuminates the algorithmic basis of an important neurobiological problem and offers strategies for novelty detection in computational systems.},
	language = {en},
	number = {51},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Dasgupta, Sanjoy and Sheehan, Timothy C. and Stevens, Charles F. and Navlakha, Saket},
	month = dec,
	year = {2018},
	pages = {13093--13098},
	file = {Dasgupta et al. - 2018 - A neural data structure for novelty detection.pdf:/Users/philmoremorrison/Zotero/storage/28XE3432/Dasgupta et al. - 2018 - A neural data structure for novelty detection.pdf:application/pdf},
}

@article{purarjomandlangrudi_fault_2013,
	title = {Fault {Detection} in {Wind} {Turbine}: {A} {Systematic} {Literature} {Review}},
	volume = {37},
	issn = {0309-524X, 2048-402X},
	shorttitle = {Fault {Detection} in {Wind} {Turbine}},
	url = {http://journals.sagepub.com/doi/10.1260/0309-524X.37.5.535},
	doi = {10.1260/0309-524X.37.5.535},
	abstract = {Wind power has become one of the popular renewable resources all over the worl anticipated to occupy 12\% of the total global electricity generation capacity by 202 harsh environment that the wind turbine operates, fault diagnostic and c monitoring are important for wind turbine safety and reliability. This paper em systematic literature review to report the most recent promotions in the wind tur diagnostic, from 2005 to 2012. The frequent faults and failures in wind tur considered and different techniques which have been used by researchers are int classified and discussed.},
	language = {en},
	number = {5},
	urldate = {2021-08-09},
	journal = {Wind Engineering},
	author = {Purarjomandlangrudi, Afrooz and Nourbakhsh, Ghavameddin and Esmalifalak, Mohammad and Tan, Andy},
	month = oct,
	year = {2013},
	pages = {535--547},
	file = {Purarjomandlangrudi et al. - 2013 - Fault Detection in Wind Turbine A Systematic Lite.pdf:/Users/philmoremorrison/Zotero/storage/FD92GZQB/Purarjomandlangrudi et al. - 2013 - Fault Detection in Wind Turbine A Systematic Lite.pdf:application/pdf},
}

@article{campbell_quantity_2013,
	title = {Quantity is {Nothing} without {Quality}: {Automated} {QA}/{QC} for {Streaming} {Environmental} {Sensor} {Data}},
	volume = {63},
	issn = {1525-3244, 0006-3568},
	shorttitle = {Quantity is {Nothing} without {Quality}},
	url = {https://academic.oup.com/bioscience/article-lookup/doi/10.1525/bio.2013.63.7.10},
	doi = {10.1525/bio.2013.63.7.10},
	abstract = {Sensor networks are revolutionizing environmental monitoring by producing massive quantities of data that are being made publically available in near real time. These data streams pose a challenge for ecologists because traditional approaches to quality assurance and quality control are no longer practical when confronted with the size of these data sets and the demands of real-time processing. Automated methods for rapidly identifying and (ideally) correcting problematic data are essential. However, advances in sensor hardware have outpaced those in software, creating a need for tools to implement automated quality assurance and quality control procedures, produce graphical and statistical summaries for review, and track the provenance of the data. Use of automated tools would enhance data integrity and reliability and would reduce delays in releasing data products. Development of community-wide standards for quality assurance and quality control would instill confidence in sensor data and would improve interoperability across environmental sensor networks.},
	language = {en},
	number = {7},
	urldate = {2021-08-09},
	journal = {BioScience},
	author = {Campbell, John L. and Rustad, Lindsey E. and Porter, John H. and Taylor, Jeffrey R. and Dereszynski, Ethan W. and Shanley, James B. and Gries, Corinna and Henshaw, Donald L. and Martin, Mary E. and Sheldon, Wade M. and Boose, Emery R.},
	month = jul,
	year = {2013},
	pages = {574--585},
	file = {Campbell et al. - 2013 - Quantity is Nothing without Quality Automated QA.pdf:/Users/philmoremorrison/Zotero/storage/7PZWZMX6/Campbell et al. - 2013 - Quantity is Nothing without Quality Automated QA.pdf:application/pdf},
}

@article{hunter_conceptual_2021,
	title = {{CONCEPTUAL} {FRAMEWORK} {FOR} {ARTIFICIAL} {INTELLIGENCE} {APPLICATIONS}},
	language = {en},
	author = {Hunter, Andrew P and Balieiro, Leonardo},
	year = {2021},
	pages = {11},
	file = {Hunter and Balieiro - 2021 - CONCEPTUAL FRAMEWORK FOR ARTIFICIAL INTELLIGENCE A.pdf:/Users/philmoremorrison/Zotero/storage/QMXXYGQK/Hunter and Balieiro - 2021 - CONCEPTUAL FRAMEWORK FOR ARTIFICIAL INTELLIGENCE A.pdf:application/pdf},
}

@article{masse_alleviating_2018,
	title = {Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1803839115},
	doi = {10.1073/pnas.1803839115},
	abstract = {Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks (ANNs) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of “catastrophic forgetting,” in which training an ANN disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of ANNs that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows ANNs to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.},
	language = {en},
	number = {44},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J.},
	month = oct,
	year = {2018},
	pages = {E10467--E10475},
	file = {Masse et al. - 2018 - Alleviating catastrophic forgetting using context-.pdf:/Users/philmoremorrison/Zotero/storage/KF475PIJ/Masse et al. - 2018 - Alleviating catastrophic forgetting using context-.pdf:application/pdf},
}

@article{gao_personalized_2019,
	title = {A {Personalized} {Lane}-{Changing} {Model} for {Advanced} {Driver} {Assistance} {System} {Based} on {Deep} {Learning} and {Spatial}-{Temporal} {Modeling}},
	volume = {7},
	issn = {2327-5626},
	url = {https://www.sae.org/content/09-07-02-0009/},
	doi = {10.4271/09-07-02-0009},
	abstract = {Lane changes are stressful maneuvers for drivers, particularly during high-speed traffic flows. However, modeling driver’s lane-changing decision and implementation process is challenging due to the complexity and uncertainty of driving behaviors. To address this issue, this article presents a personalized Lane-Changing Model (LCM) for Advanced Driver Assistance System (ADAS) based on deep learning method. The LCM contains three major computational components.},
	language = {en},
	number = {2},
	urldate = {2021-08-09},
	journal = {SAE International Journal of Transportation Safety},
	author = {Gao, Jun and Yi, Jiangang and Zhu, Honghui and Murphey, Yi Lu},
	month = nov,
	year = {2019},
	pages = {09--07--02--0009},
	file = {Gao et al. - 2019 - A Personalized Lane-Changing Model for Advanced Dr.pdf:/Users/philmoremorrison/Zotero/storage/E3THK66P/Gao et al. - 2019 - A Personalized Lane-Changing Model for Advanced Dr.pdf:application/pdf},
}

@article{esser_convolutional_2016,
	title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1604850113},
	doi = {10.1073/pnas.1604850113},
	abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (
              i
              ) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (
              ii
              ) perform inference while preserving the hardware’s underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively {\textgreater}6,000 frames/s per Watt), and (
              iii
              ) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
	language = {en},
	number = {41},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and di Nolfo, Carmelo and Datta, Pallab and Amir, Arnon and Taba, Brian and Flickner, Myron D. and Modha, Dharmendra S.},
	month = oct,
	year = {2016},
	pages = {11441--11446},
	file = {Esser et al. - 2016 - Convolutional networks for fast, energy-efficient .pdf:/Users/philmoremorrison/Zotero/storage/JLSVLW6A/Esser et al. - 2016 - Convolutional networks for fast, energy-efficient .pdf:application/pdf},
}

@article{pelt_mixed-scale_2018,
	title = {A mixed-scale dense convolutional neural network for image analysis},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1715832114},
	doi = {10.1073/pnas.1715832114},
	abstract = {Deep convolutional neural networks have been successfully applied to many image-processing problems in recent works. Popular network architectures often add additional operations and connections to the standard architecture to enable training deeper networks. To achieve accurate results in practice, a large number of trainable parameters are often required. Here, we introduce a network architecture based on using dilated convolutions to capture features at different image scales and densely connecting all feature maps with each other. The resulting architecture is able to achieve accurate results with relatively few parameters and consists of a single set of operations, making it easier to implement, train, and apply in practice, and automatically adapts to different problems. We compare results of the proposed network architecture with popular existing architectures for several segmentation problems, showing that the proposed architecture is able to achieve accurate results with fewer parameters, with a reduced risk of overfitting the training data.},
	language = {en},
	number = {2},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Pelt, Daniël M. and Sethian, James A.},
	month = jan,
	year = {2018},
	pages = {254--259},
	file = {Pelt and Sethian - 2018 - A mixed-scale dense convolutional neural network f.pdf:/Users/philmoremorrison/Zotero/storage/JBZRWKM5/Pelt and Sethian - 2018 - A mixed-scale dense convolutional neural network f.pdf:application/pdf},
}

@article{ghosal_explainable_2018,
	title = {An explainable deep machine vision framework for plant stress phenotyping},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1716999115},
	doi = {10.1073/pnas.1716999115},
	abstract = {Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework’s ability to identify and classify a diverse set of foliar stresses in soybean [
              Glycine max
              (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.},
	language = {en},
	number = {18},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ghosal, Sambuddha and Blystone, David and Singh, Asheesh K. and Ganapathysubramanian, Baskar and Singh, Arti and Sarkar, Soumik},
	month = may,
	year = {2018},
	pages = {4613--4618},
	file = {Ghosal et al. - 2018 - An explainable deep machine vision framework for p.pdf:/Users/philmoremorrison/Zotero/storage/NWK2FXV9/Ghosal et al. - 2018 - An explainable deep machine vision framework for p.pdf:application/pdf},
}

@article{mobadersany_predicting_2018,
	title = {Predicting cancer outcomes from histology and genomics using convolutional networks},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1717139115},
	doi = {10.1073/pnas.1717139115},
	abstract = {Cancer histology reflects underlying molecular processes and disease progression and contains rich phenotypic information that is predictive of patient outcomes. In this study, we show a computational approach for learning patient outcomes from digital pathology images using deep learning to combine the power of adaptive machine learning algorithms with traditional survival models. We illustrate how these survival convolutional neural networks (SCNNs) can integrate information from both histology images and genomic biomarkers into a single unified framework to predict time-to-event outcomes and show prediction accuracy that surpasses the current clinical paradigm for predicting the overall survival of patients diagnosed with glioma. We use statistical sampling techniques to address challenges in learning survival from histology images, including tumor heterogeneity and the need for large training cohorts. We also provide insights into the prediction mechanisms of SCNNs, using heat map visualization to show that SCNNs recognize important structures, like microvascular proliferation, that are related to prognosis and that are used by pathologists in grading. These results highlight the emerging role of deep learning in precision medicine and suggest an expanding utility for computational analysis of histology in the future practice of pathology.},
	language = {en},
	number = {13},
	urldate = {2021-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mobadersany, Pooya and Yousefi, Safoora and Amgad, Mohamed and Gutman, David A. and Barnholtz-Sloan, Jill S. and Velázquez Vega, José E. and Brat, Daniel J. and Cooper, Lee A. D.},
	month = mar,
	year = {2018},
	pages = {E2970--E2979},
	file = {Mobadersany et al. - 2018 - Predicting cancer outcomes from histology and geno.pdf:/Users/philmoremorrison/Zotero/storage/T4LKMNFY/Mobadersany et al. - 2018 - Predicting cancer outcomes from histology and geno.pdf:application/pdf},
}

@article{setiono_automatic_2005,
	title = {Automatic knowledge extraction from survey data: learning \textit{{M}} -of- \textit{{N}} constructs using a hybrid approach},
	volume = {56},
	issn = {0160-5682, 1476-9360},
	shorttitle = {Automatic knowledge extraction from survey data},
	url = {https://www.tandfonline.com/doi/full/10.1057/palgrave.jors.2601807},
	doi = {10.1057/palgrave.jors.2601807},
	language = {en},
	number = {1},
	urldate = {2021-08-09},
	journal = {Journal of the Operational Research Society},
	author = {Setiono, R and Pan, S-L and Hsieh, M-H and Azcarraga, A},
	month = jan,
	year = {2005},
	pages = {3--14},
	file = {Setiono et al. - 2005 - Automatic knowledge extraction from survey data l.pdf:/Users/philmoremorrison/Zotero/storage/ERQUYIGD/Setiono et al. - 2005 - Automatic knowledge extraction from survey data l.pdf:application/pdf},
}

@article{cheggaga_new_2013,
	title = {New {Neural} {Networks} {Strategy} {Used} to {Improve} {Wind} {Speed} {Forecasting}},
	volume = {37},
	issn = {0309-524X, 2048-402X},
	url = {http://journals.sagepub.com/doi/10.1260/0309-524X.37.4.369},
	doi = {10.1260/0309-524X.37.4.369},
	abstract = {Wind speed forecasting is critical for wind energy conversion systems since i influences the issues such as the scheduling of a power system, and the dynamic co the wind turbine. The wind forecast problem aims to find an estimate f(t + k) of t vector y(f + k) based on the previous n measurements. Artificial neural networks technique basically used to map random input vector (s) to the corresponding output vector without pre-assuming any fixed relationship between them. D network structures, learning rates, and inputs are believed to result in different accuracies. However, in literature it was discovered that, different inputs and learn as well as model structures, directly influence the forecast accuracy. In this paper, w a robust and reliable forecast method by applying a new learning Strategy. This ne allows a renewal learning data in time. A simple multilayer perceptron (M Levenberg-Marquardt learning algorithm technique is used for predicting the win For our algorithm a neural network is developed to estimate just one value f(t+ 1), taken up with a new set of learning enriched by data freshly measured. The wind are the hourly mean wind speed collected at an observation sites in Ksar El (Algeria). Simulation results are reported, showing that the estimated wind speed predicted by the proposed learning algorithm technique, are in good agreement w experimental measured values. The present paper deals with the developme adaptive neural network model for the hourly forecasting of wind speed.},
	language = {en},
	number = {4},
	urldate = {2021-08-09},
	journal = {Wind Engineering},
	author = {Cheggaga, Nawal},
	month = aug,
	year = {2013},
	pages = {369--379},
	file = {Cheggaga - 2013 - New Neural Networks Strategy Used to Improve Wind .pdf:/Users/philmoremorrison/Zotero/storage/V9DBEGVT/Cheggaga - 2013 - New Neural Networks Strategy Used to Improve Wind .pdf:application/pdf},
}

@article{asher_identification_2019,
	title = {Identification and {Review} of the {Research} {Gaps} {Preventing} a {Realization} of {Optimal} {Energy} {Management} {Strategies} in {Vehicles}},
	volume = {8},
	issn = {2167-4205},
	url = {https://www.sae.org/content/08-08-02-0009/},
	doi = {10.4271/08-08-02-0009},
	abstract = {The development of new vehicle control strategies that achieve improved fuel economy (FE) is an active subject of research due to the economic, environmental, and societal impact of transportation. These control strategies can be classified as either driving behavior modifications (e.g., Eco-Driving, Eco-Routing) or powertrain operation modifications (e.g., an Optimal Energy Management Strategy, or Optimal EMS). This literature review is focused on the Optimal EMS and seeks to develop a novel understanding of the current research gaps and to provide a novel comprehensive overview of initial studies addressing the identified research gaps. Research gaps are derived by utilizing a systems-level viewpoint of an Optimal EMS realization in vehicles and studying the subsystem integration readiness levels (IRLs). Identified research gaps include (1) incorporation of both perception and planning subsystems, (2) studying the effects of mispredictions on the planning subsystem, and (3) physical demonstrations of the planning subsystem. Studies which have begun to fill each research gap are identified, and recommendations are presented for future research to bridge each research gap. It is the authors’ contention that once the identified research gaps are closed by future studies, Optimal EMS will be achievable in modern vehicles resulting in improved transportation sustainability.},
	language = {en},
	number = {2},
	urldate = {2021-08-09},
	journal = {SAE International Journal of Alternative Powertrains},
	author = {Asher, Zachary D. and Patil, Amol A. and Wifvat, Van T. and Frank, Andrew A. and Samuelsen, Scott and Bradley, Thomas H.},
	month = nov,
	year = {2019},
	pages = {08--08--02--0009},
	file = {Asher et al. - 2019 - Identification and Review of the Research Gaps Pre.pdf:/Users/philmoremorrison/Zotero/storage/J3KWYJBP/Asher et al. - 2019 - Identification and Review of the Research Gaps Pre.pdf:application/pdf},
}

@article{jaeger_harnessing_2004,
	title = {Harnessing {Nonlinearity}: {Predicting} {Chaotic} {Systems} and {Saving} {Energy} in {Wireless} {Communication}},
	volume = {304},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Harnessing {Nonlinearity}},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1091277},
	doi = {10.1126/science.1091277},
	language = {en},
	number = {5667},
	urldate = {2021-08-09},
	journal = {Science},
	author = {Jaeger, H.},
	month = apr,
	year = {2004},
	pages = {78--80},
	file = {Jaeger - 2004 - Harnessing Nonlinearity Predicting Chaotic System.pdf:/Users/philmoremorrison/Zotero/storage/FJLY3T66/Jaeger - 2004 - Harnessing Nonlinearity Predicting Chaotic System.pdf:application/pdf},
}

@article{reed_neural_1999,
	title = {Neural {Smithing}: {Supervised} {Learning} in {Feedforward} {Artificial} {Neural} {Networks}},
	shorttitle = {Neural {Smithing}},
	url = {https://direct.mit.edu/books/book/2736/Neural-SmithingSupervised-Learning-in-Feedforward},
	doi = {10.7551/mitpress/4937.001.0001},
	abstract = {Artificial neural networks are nonlinear mapping systems whose structure is loosely based on principles observed in the nervous systems of humans and animals. T},
	language = {en},
	urldate = {2021-08-13},
	author = {Reed, Russell and Marks, Robert J.},
	month = feb,
	year = {1999},
	file = {Snapshot:/Users/philmoremorrison/Zotero/storage/M6UN4D9K/Neural-SmithingSupervised-Learning-in-Feedforward.html:text/html},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	language = {en},
	author = {Rumelhart, David E and Hintont, Geoffrey E and Williams, Ronald J},
	year = {1986},
	pages = {4},
	file = {Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf:/Users/philmoremorrison/Zotero/storage/2P2YUZ5U/Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf:application/pdf},
}

@article{nielsen_neural_2015,
	title = {Neural {Networks} and {Deep} {Learning}},
	url = {http://neuralnetworksanddeeplearning.com},
	language = {en},
	urldate = {2021-08-13},
	author = {Nielsen, Michael A.},
	year = {2015},
	note = {Publisher: Determination Press},
	file = {Snapshot:/Users/philmoremorrison/Zotero/storage/BIYQNA96/chap2.html:text/html},
}

@article{geiger_tadgan_2020,
	title = {{TadGAN}: {Time} {Series} {Anomaly} {Detection} {Using} {Generative} {Adversarial} {Networks}},
	shorttitle = {{TadGAN}},
	url = {http://arxiv.org/abs/2009.07769},
	abstract = {Time series anomalies can offer information relevant to critical situations facing various ﬁelds, from ﬁnance and aerospace to the IT, security, and medical domains. However, detecting anomalies in time series data is particularly challenging due to the vague deﬁnition of anomalies and said data’s frequent lack of labels and highly complex temporal correlations. Current state-of-the-art unsupervised machine learning methods for anomaly detection suffer from scalability and portability issues, and may have high false positive rates. In this paper, we propose TadGAN, an unsupervised anomaly detection approach built on Generative Adversarial Networks (GANs). To capture the temporal correlations of time series distributions, we use LSTM Recurrent Neural Networks as base models for Generators and Critics. TadGAN is trained with cycle consistency loss to allow for effective time-series data reconstruction. We further propose several novel methods to compute reconstruction errors, as well as different approaches to combine reconstruction errors and Critic outputs to compute anomaly scores. To demonstrate the performance and generalizability of our approach, we test several anomaly scoring techniques and report the best-suited one. We compare our approach to 8 baseline anomaly detection methods on 11 datasets from multiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter. The results show that our approach can effectively detect anomalies and outperform baseline methods in most cases (6 out of 11). Notably, our method has the highest averaged F1 score across all the datasets. Our code is open source and is available as a benchmarking tool.},
	language = {en},
	urldate = {2021-08-16},
	journal = {arXiv:2009.07769 [cs, stat]},
	author = {Geiger, Alexander and Liu, Dongyu and Alnegheimish, Sarah and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	month = nov,
	year = {2020},
	note = {arXiv: 2009.07769},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Geiger et al. - 2020 - TadGAN Time Series Anomaly Detection Using Genera.pdf:/Users/philmoremorrison/Zotero/storage/55UIP69Y/Geiger et al. - 2020 - TadGAN Time Series Anomaly Detection Using Genera.pdf:application/pdf},
}

@article{schlegl_unsupervised_2017,
	title = {Unsupervised {Anomaly} {Detection} with {Generative} {Adversarial} {Networks} to {Guide} {Marker} {Discovery}},
	url = {http://arxiv.org/abs/1703.05921},
	abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their ﬁt into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identiﬁes anomalous images, such as images containing retinal ﬂuid or hyperreﬂective foci.},
	language = {en},
	urldate = {2021-08-18},
	journal = {arXiv:1703.05921 [cs]},
	author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.05921},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Schlegl et al. - 2017 - Unsupervised Anomaly Detection with Generative Adv.pdf:/Users/philmoremorrison/Zotero/storage/88GUVPCC/Schlegl et al. - 2017 - Unsupervised Anomaly Detection with Generative Adv.pdf:application/pdf},
}

@article{hodge_survey_2004,
	title = {A {Survey} of {Outlier} {Detection} {Methodologies}},
	volume = {22},
	issn = {0269-2821},
	url = {http://link.springer.com/10.1023/B:AIRE.0000045502.10941.a9},
	doi = {10.1023/B:AIRE.0000045502.10941.a9},
	abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating eﬀect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
	language = {en},
	number = {2},
	urldate = {2021-08-19},
	journal = {Artificial Intelligence Review},
	author = {Hodge, Victoria and Austin, Jim},
	month = oct,
	year = {2004},
	pages = {85--126},
	file = {Hodge and Austin - 2004 - A Survey of Outlier Detection Methodologies.pdf:/Users/philmoremorrison/Zotero/storage/J6MV7NFK/Hodge and Austin - 2004 - A Survey of Outlier Detection Methodologies.pdf:application/pdf},
}

@article{kriegel_outlier_2010,
	title = {Outlier {Detection} {Techniques}},
	language = {en},
	author = {Kriegel, Hans-Peter and Kröger, Peer and Zimek, Arthur},
	year = {2010},
	pages = {73},
	file = {Kriegel et al. - 2010 - Outlier Detection Techniques.pdf:/Users/philmoremorrison/Zotero/storage/BGGS3BVX/Kriegel et al. - 2010 - Outlier Detection Techniques.pdf:application/pdf},
}

@article{britz_recurrent_nodate,
	title = {Recurrent {Neural} {Networks} {Tutorial}, {Part} 3 – {Backpropagation} {Through} {Time} and {Vanishing} {Gradients}},
	language = {en},
	author = {Britz, Denny},
	pages = {14},
	file = {Britz - Recurrent Neural Networks Tutorial, Part 3 – Backp.pdf:/Users/philmoremorrison/Zotero/storage/U4QNJGDE/Britz - Recurrent Neural Networks Tutorial, Part 3 – Backp.pdf:application/pdf},
}

@article{chung_empirical_2014,
	title = {Empirical {Evaluation} of {Gated} {Recurrent} {Neural} {Networks} on {Sequence} {Modeling}},
	url = {http://arxiv.org/abs/1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	language = {en},
	urldate = {2021-08-19},
	journal = {arXiv:1412.3555 [cs]},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3555},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf:/Users/philmoremorrison/Zotero/storage/CEVBEVFS/Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf:application/pdf},
}

@article{jozefowicz_empirical_nodate,
	title = {An {Empirical} {Exploration} of {Recurrent} {Network} {Architectures}},
	abstract = {The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difﬁcult to train. The Long Short-Term Memory (LSTM) is a speciﬁc RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM’s architecture appears to be ad-hoc so it is not clear if it is optimal, and the signiﬁcance of its individual components is unclear.},
	language = {en},
	author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
	pages = {9},
	file = {Jozefowicz et al. - An Empirical Exploration of Recurrent Network Arch.pdf:/Users/philmoremorrison/Zotero/storage/IVLP6YEB/Jozefowicz et al. - An Empirical Exploration of Recurrent Network Arch.pdf:application/pdf},
}

@article{grubbs_procedures_1969,
	title = {Procedures for {Detecting} {Outlying} {Observations} in {Samples}},
	volume = {11},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1969.10490657},
	doi = {10.1080/00401706.1969.10490657},
	language = {en},
	number = {1},
	urldate = {2021-08-19},
	journal = {Technometrics},
	author = {Grubbs, Frank E.},
	month = feb,
	year = {1969},
	pages = {1--21},
	file = {Grubbs - 1969 - Procedures for Detecting Outlying Observations in .pdf:/Users/philmoremorrison/Zotero/storage/CLB6U5GG/Grubbs - 1969 - Procedures for Detecting Outlying Observations in .pdf:application/pdf},
}

@misc{raj_deepant_2020,
	title = {{DeepAnT} — {Unsupervised} {Anomaly} {Detection} for {Time} {Series}},
	url = {https://towardsdatascience.com/deepant-unsupervised-anomaly-detection-for-time-series-97c5308546ea},
	abstract = {The beauty of patterns is observed only when you have the way to find a needle in the haystack!},
	language = {en},
	urldate = {2021-08-19},
	journal = {Medium},
	author = {Raj, Monik},
	month = jul,
	year = {2020},
	file = {Snapshot:/Users/philmoremorrison/Zotero/storage/Q6BWXA73/deepant-unsupervised-anomaly-detection-for-time-series-97c5308546ea.html:text/html},
}

@inproceedings{kieu_outlier_2019,
	address = {Macao, China},
	title = {Outlier {Detection} for {Time} {Series} with {Recurrent} {Autoencoder} {Ensembles}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/378},
	doi = {10.24963/ijcai.2019/378},
	abstract = {We propose two solutions to outlier detection in time series based on recurrent autoencoder ensembles. The solutions exploit autoencoders built using sparsely-connected recurrent neural networks (S-RNNs). Such networks make it possible to generate multiple autoencoders with different neural network connection structures. The two solutions are ensemble frameworks, speciﬁcally an independent framework and a shared framework, both of which combine multiple S-RNN based autoencoders to enable outlier detection. This ensemble-based approach aims to reduce the effects of some autoencoders being overﬁtted to outliers, this way improving overall detection quality. Experiments with two real-world time series data sets, including univariate and multivariate time series, offer insight into the design properties of the proposed ensemble frameworks and demonstrate that the proposed frameworks are capable of outperforming both baselines and the state-of-the-art methods.},
	language = {en},
	urldate = {2021-08-19},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Kieu, Tung and Yang, Bin and Guo, Chenjuan and Jensen, Christian S.},
	month = aug,
	year = {2019},
	pages = {2725--2732},
	file = {Kieu et al. - 2019 - Outlier Detection for Time Series with Recurrent A.pdf:/Users/philmoremorrison/Zotero/storage/UPZS66P2/Kieu et al. - 2019 - Outlier Detection for Time Series with Recurrent A.pdf:application/pdf},
}

@article{malhotra_long_2015,
	title = {Long {Short} {Term} {Memory} {Networks} for {Anomaly} {Detection} in {Time} {Series}},
	abstract = {Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The eﬃcacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Malhotra, Pankaj and Vig, Lovekesh and Shroﬀ, Gautam and Agarwal, Puneet},
	year = {2015},
	pages = {6},
	file = {Malhotra et al. - 2015 - Long Short Term Memory Networks for Anomaly Detect.pdf:/Users/philmoremorrison/Zotero/storage/Z43FYEFC/Malhotra et al. - 2015 - Long Short Term Memory Networks for Anomaly Detect.pdf:application/pdf},
}

@article{malhotra_lstm-based_nodate,
	title = {{LSTM}-based {Encoder}-{Decoder} for {Multi}-sensor {Anomaly} {Detection}},
	abstract = {Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct ‘normal’ time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two realworld engine datasets with both predictive and unpredictable behavior. We show that EncDecAD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).},
	language = {en},
	author = {Malhotra, Pankaj and Ramakrishnan, Anusha and Anand, Gaurangi and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
	year = {2016},
	pages = {5},
	file = {Malhotra et al. - LSTM-based Encoder-Decoder for Multi-sensor Anomal.pdf:/Users/philmoremorrison/Zotero/storage/2RS2PJXL/Malhotra et al. - LSTM-based Encoder-Decoder for Multi-sensor Anomal.pdf:application/pdf},
}

@article{nguyen_forecasting_2021,
	title = {Forecasting and {Anomaly} {Detection} approaches using {LSTM} and {LSTM} {Autoencoder} techniques with the applications in supply chain management},
	volume = {57},
	issn = {02684012},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S026840122031481X},
	doi = {10.1016/j.ijinfomgt.2020.102282},
	abstract = {Making appropriate decisions is indeed a key factor to help companies facing challenges from supply chains nowadays. In this paper, we propose two data-driven approaches that allow making better decisions in supply chain management. In particular, we suggest a Long Short Term Memory (LSTM) network-based method for forecasting multivariate time series data and an LSTM Autoencoder network-based method combined with a oneclass support vector machine algorithm for detecting anomalies in sales. Unlike other approaches, we recom­ mend combining external and internal company data sources for the purpose of enhancing the performance of forecasting algorithms using multivariate LSTM with the optimal hyperparameters. In addition, we also propose a method to optimize hyperparameters for hybrid algorithms for detecting anomalies in time series data. The proposed approaches will be applied to both benchmarking datasets and real data in fashion retail. The obtained results show that the LSTM Autoencoder based method leads to better performance for anomaly detection compared to the LSTM based method suggested in a previous study. The proposed forecasting method for multivariate time series data also performs better than some other methods based on a dataset provided by NASA.},
	language = {en},
	urldate = {2021-08-19},
	journal = {International Journal of Information Management},
	author = {Nguyen, H.D. and Tran, K.P. and Thomassey, S. and Hamad, M.},
	month = apr,
	year = {2021},
	pages = {102282},
	file = {Nguyen et al. - 2021 - Forecasting and Anomaly Detection approaches using.pdf:/Users/philmoremorrison/Zotero/storage/BBV54FKM/Nguyen et al. - 2021 - Forecasting and Anomaly Detection approaches using.pdf:application/pdf},
}

@article{alfeo_using_2020,
	title = {Using an autoencoder in the design of an anomaly detector for smart manufacturing},
	volume = {136},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865520302269},
	doi = {10.1016/j.patrec.2020.06.008},
	language = {en},
	urldate = {2021-08-19},
	journal = {Pattern Recognition Letters},
	author = {Alfeo, Antonio L. and Cimino, Mario G.C.A. and Manco, Giuseppe and Ritacco, Ettore and Vaglini, Gigliola},
	month = aug,
	year = {2020},
	pages = {272--278},
	file = {Alfeo et al. - 2020 - Using an autoencoder in the design of an anomaly d.pdf:/Users/philmoremorrison/Zotero/storage/37EAVIJA/Alfeo et al. - 2020 - Using an autoencoder in the design of an anomaly d.pdf:application/pdf},
}

@inproceedings{luzar_actuators_2012,
	address = {Miedzyzdroje, Poland},
	title = {Actuators and sensors fault diagnosis with dynamic, state-space neural networks},
	isbn = {978-1-4673-2124-2 978-1-4673-2121-1 978-1-4673-2123-5},
	url = {http://ieeexplore.ieee.org/document/6347889/},
	doi = {10.1109/MMAR.2012.6347889},
	abstract = {In this paper, the actuators and sensors fault detection and localization using a system model is considered. To obtain the system model, the neural network modeling is used. The artiﬁcial feedforward neural network with dynamic neurons in the state-space representation is proposed. To estimate the neural network parameters, the Adaptive Random Search algorithm with projection is used. To identify, which of actuators or sensors is faulty, the system input estimator is proposed. The input and output residuals being the difference between the system input and output and its estimates are used to detect and isolate the faults. The ﬁnal part of the paper presents an application study, which clearly conﬁrms the effectiveness of the proposed approach.},
	language = {en},
	urldate = {2021-08-19},
	booktitle = {2012 17th {International} {Conference} on {Methods} \& {Models} in {Automation} \& {Robotics} ({MMAR})},
	publisher = {IEEE},
	author = {Luzar, Marcel and Czajkowski, Andrzej and Witczak, Marcin and Korbicz, Jozef},
	month = aug,
	year = {2012},
	pages = {196--201},
	file = {Luzar et al. - 2012 - Actuators and sensors fault diagnosis with dynamic.pdf:/Users/philmoremorrison/Zotero/storage/JXENDLBQ/Luzar et al. - 2012 - Actuators and sensors fault diagnosis with dynamic.pdf:application/pdf},
}

@incollection{zbikowski_black-box_1996,
	title = {{BLACK}-{BOX} {MODELING} {WITH} {STATE}-{SPACE} {NEURAL} {NETWORKS}},
	volume = {15},
	isbn = {978-981-02-2557-5 978-981-283-038-8},
	url = {http://www.worldscientific.com/doi/abs/10.1142/9789812830388_0008},
	abstract = {Neural network black-box modeling is usually performed using nonlinear inputoutput models. The goal of this paper is to show that there are advantages in using nonlinear state-space models, which constitute a larger class of nonlinear dynamical models, and their corresponding state-space neural predictors. We recall the fundamentals of both input-output and state-space black-box modeling, and show the state-space neural networks to be potentially more efficient and more parsimonious than their conventional input-output counterparts. This is examplified on simulated processes as well as on a real one, the hydraulic actuator of a robot arm.},
	language = {en},
	urldate = {2021-08-19},
	booktitle = {World {Scientific} {Series} in {Robotics} and {Intelligent} {Systems}},
	publisher = {WORLD SCIENTIFIC},
	author = {Rivals, Isabelle and Personnaz, Léon},
	collaborator = {Zbikowski, R and Hunt, K J},
	month = apr,
	year = {1996},
	doi = {10.1142/9789812830388_0008},
	pages = {237--264},
	file = {Rivals and Personnaz - 1996 - BLACK-BOX MODELING WITH STATE-SPACE NEURAL NETWORK.pdf:/Users/philmoremorrison/Zotero/storage/7YZXAQAU/Rivals and Personnaz - 1996 - BLACK-BOX MODELING WITH STATE-SPACE NEURAL NETWORK.pdf:application/pdf},
}

@article{van_lint_freeway_2002,
	title = {Freeway {Travel} {Time} {Prediction} with {State}-{Space} {Neural} {Networks}: {Modeling} {State}-{Space} {Dynamics} with {Recurrent} {Neural} {Networks}},
	volume = {1811},
	issn = {0361-1981, 2169-4052},
	shorttitle = {Freeway {Travel} {Time} {Prediction} with {State}-{Space} {Neural} {Networks}},
	url = {http://journals.sagepub.com/doi/10.3141/1811-04},
	doi = {10.3141/1811-04},
	abstract = {An approach to freeway travel time prediction based on recurrent neural networks is presented. Travel time prediction requires a modeling approach that is capable of dealing with complex nonlinear spatio-temporal relationships among flows, speeds, and densities. Based on the literature, feedforward neural networks are a class of mathematical models well suited for solving this problem. A drawback of the feed-forward approach is that the size and composition of the input time series are inherently design choices and thus fixed for all input. This may lead to unnecessarily large models. Moreover, for different traffic conditions, different sizes and compositions of input time series may be required, a requirement not satisfied by any feedforward data-driven method. The recurrent neural network topology presented is capable of dealing with the spatiotemporal relationships implicitly. The topology of this neural net is derived from a state-space formulation of the travel time prediction problem, which is in line with traffic flow theory. The performance of several versions of this state-space neural network was tested on synthetic data from a densely used highway stretch in the Netherlands. The neural network models were capable of accurately predicting travel times experienced, producing about zero mean normally distributed residuals, rarely outside 10\% of the real expected travel times. Moreover, analyses of the internal states and weight configurations revealed that the neural networks could develop an internal model linked to the underlying traffic processes.},
	language = {en},
	number = {1},
	urldate = {2021-08-19},
	journal = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {van Lint, J. W. C. and Hoogendoorn, S. P. and van Zuylen, H. J.},
	month = jan,
	year = {2002},
	pages = {30--39},
	file = {van Lint et al. - 2002 - Freeway Travel Time Prediction with State-Space Ne.pdf:/Users/philmoremorrison/Zotero/storage/6PLY82SB/van Lint et al. - 2002 - Freeway Travel Time Prediction with State-Space Ne.pdf:application/pdf},
}

@article{van_lint_accurate_2005,
	title = {Accurate freeway travel time prediction with state-space neural networks under missing data},
	volume = {13},
	issn = {0968090X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0968090X0500029X},
	doi = {10.1016/j.trc.2005.03.001},
	abstract = {Accuracy and robustness with respect to missing or corrupt input data are two key characteristics for any travel time prediction model that is to be applied in a real-time environment (e.g. for display on variable message signs on freeways). This article proposes a freeway travel time prediction framework that exhibits both qualities. The framework exploits a recurrent neural network topology, the so-called statespace neural network (SSNN), with preprocessing strategies based on imputation. Although the SSNN model is a neural network, its design (in terms of input- and model selection) is not ‘‘black box’’ nor location-speciﬁc. Instead, it is based on the lay-out of the freeway stretch of interest. In this sense, the SSNN model combines the generality of neural network approaches, with traﬃc related (‘‘white-box’’) design. Robustness to missing data is tackled by means of simple imputation (data replacement) schemes, such as exponential forecasts and spatial interpolation. Although there are clear theoretical shortcomings to ‘‘simple’’ imputation schemes to remedy input failure, our results indicate that their use is justiﬁed in this particular application. The SSNN model appears to be robust to the ‘‘damage’’ done by these imputation schemes. This is true for both incidental (random) and structural input failure. We demonstrate that the SSNN travel time prediction framework yields good accurate and robust travel time predictions on both synthetic and real data.},
	language = {en},
	number = {5-6},
	urldate = {2021-08-19},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {van Lint, J.W.C. and Hoogendoorn, S.P. and van Zuylen, H.J.},
	month = oct,
	year = {2005},
	pages = {347--369},
	file = {van Lint et al. - 2005 - Accurate freeway travel time prediction with state.pdf:/Users/philmoremorrison/Zotero/storage/8AWF24A5/van Lint et al. - 2005 - Accurate freeway travel time prediction with state.pdf:application/pdf},
}

@book{durbin_time_2012,
	series = {Oxford {Statistical} {Science} {Series}},
	title = {Time {Series} {Analysis} by {State} {Space} {Methods}: {Second} {Edition}},
	isbn = {978-0-19-964117-8},
	url = {https://books.google.com/books?id=fOq39Zh0olQC},
	publisher = {OUP Oxford},
	author = {Durbin, J. and Koopman, S.J.},
	year = {2012},
	lccn = {2011945385},
}

@misc{brownlee_multi-step_2018,
	title = {Multi-{Step} {LSTM} {Time} {Series} {Forecasting} {Models} for {Power} {Usage}},
	url = {https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/},
	abstract = {Given the rise of smart electricity meters and the wide adoption of electricity generation technology like solar panels, there is […]},
	language = {en-US},
	urldate = {2021-08-21},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = oct,
	year = {2018},
	file = {Snapshot:/Users/philmoremorrison/Zotero/storage/2IC9Z7DU/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumptio.html:text/html},
}

@article{baker_emergent_2020,
	title = {Emergent {Tool} {Use} {From} {Multi}-{Agent} {Autocurricula}},
	url = {http://arxiv.org/abs/1909.07528},
	abstract = {Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.},
	urldate = {2021-08-22},
	journal = {arXiv:1909.07528 [cs, stat]},
	author = {Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
	month = feb,
	year = {2020},
	note = {arXiv: 1909.07528},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
	file = {arXiv Fulltext PDF:/Users/philmoremorrison/Zotero/storage/KM2CHR2T/Baker et al. - 2020 - Emergent Tool Use From Multi-Agent Autocurricula.pdf:application/pdf;arXiv.org Snapshot:/Users/philmoremorrison/Zotero/storage/DQQ4NTWW/1909.html:text/html},
}

@article{fernando_neural_2020,
	title = {Neural memory plasticity for medical anomaly detection},
	volume = {127},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608020301313},
	doi = {10.1016/j.neunet.2020.04.011},
	abstract = {In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restrict them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.},
	language = {en},
	urldate = {2021-08-28},
	journal = {Neural Networks},
	author = {Fernando, Tharindu and Denman, Simon and Ahmedt-Aristizabal, David and Sridharan, Sridha and Laurens, Kristin R. and Johnston, Patrick and Fookes, Clinton},
	month = jul,
	year = {2020},
	pages = {67--81},
	file = {Fernando et al. - 2020 - Neural memory plasticity for medical anomaly detec.pdf:/Users/philmoremorrison/Zotero/storage/4LSYE5XQ/Fernando et al. - 2020 - Neural memory plasticity for medical anomaly detec.pdf:application/pdf},
}

@article{zhang_deep_2019,
	title = {A {Deep} {Neural} {Network} for {Unsupervised} {Anomaly} {Detection} and {Diagnosis} in {Multivariate} {Time} {Series} {Data}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/3942},
	doi = {10.1609/aaai.v33i01.33011409},
	abstract = {Nowadays, multivariate time series data are increasingly collected in various real world systems, e.g., power plants, wearable devices, etc. Anomaly detection and diagnosis in multivariate time series refer to identifying abnormal status in certain time steps and pinpointing the root causes. Building such a system, however, is challenging since it not only requires to capture the temporal dependency in each time series, but also need encode the inter-correlations between different pairs of time series. In addition, the system should be robust to noise and provide operators with different levels of anomaly scores based upon the severity of different incidents. Despite the fact that a number of unsupervised anomaly detection algorithms have been developed, few of them can jointly address these challenges. In this paper, we propose a Multi-Scale Convolutional Recurrent Encoder-Decoder (MSCRED), to perform anomaly detection and diagnosis in multivariate time series data. Speciﬁcally, MSCRED ﬁrst constructs multi-scale (resolution) signature matrices to characterize multiple levels of the system statuses in different time steps. Subsequently, given the signature matrices, a convolutional encoder is employed to encode the inter-sensor (time series) correlations and an attention based Convolutional Long-Short Term Memory (ConvLSTM) network is developed to capture the temporal patterns. Finally, based upon the feature maps which encode the inter-sensor correlations and temporal information, a convolutional decoder is used to reconstruct the input signature matrices and the residual signature matrices are further utilized to detect and diagnose anomalies. Extensive empirical studies based on a synthetic dataset and a real power plant dataset demonstrate that MSCRED can outperform state-ofthe-art baseline methods.},
	language = {en},
	urldate = {2021-08-28},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Zhang, Chuxu and Song, Dongjin and Chen, Yuncong and Feng, Xinyang and Lumezanu, Cristian and Cheng, Wei and Ni, Jingchao and Zong, Bo and Chen, Haifeng and Chawla, Nitesh V.},
	month = jul,
	year = {2019},
	pages = {1409--1416},
	file = {Zhang et al. - 2019 - A Deep Neural Network for Unsupervised Anomaly Det.pdf:/Users/philmoremorrison/Zotero/storage/84M4RTRA/Zhang et al. - 2019 - A Deep Neural Network for Unsupervised Anomaly Det.pdf:application/pdf},
}

@article{chawla_bidirectional_2019,
	title = {Bidirectional {LSTM} {Autoencoder} for {Sequence} {Based} {Anomaly} {Detection} in {Cyber} {Security}},
	issn = {1473-804X},
	url = {https://edas.info/doi/10.5013/IJSSST.a.20.05.07},
	doi = {10.5013/IJSSST.a.20.05.07},
	abstract = {Cyber-security is concerned with protecting information, a vital asset in today’s world. The volume of data that is generated can be usefully analyzed when cyber-security systems are effectively implemented with the aid of software support. Our approach is to determine normal behavior of a system based on sequences of system call traces made by the kernel processes in the system. This paper describes a robust and computationally efficient anomaly based host based intrusion detection system using an Encoder-Decoder mechanism. Using CuDNNLSTM networks, it is possible to obtain a set of comparable results with reduced training times. The Bidirectional Encoder and a unidirectional Decoder is trained on normal call sequences in the ADFA-LD dataset. Intrusion Detection is evaluated based on determining the probability of a sequence being reconstructed by the model representing normal data. The sequences with a low probability value are classified as an anomaly.},
	language = {en},
	urldate = {2021-08-28},
	journal = {International journal of simulation: systems, science \& technology},
	author = {Chawla, Ashima and Lee, Brian and Jacob, Paul and Fallon, Sheila},
	month = oct,
	year = {2019},
	file = {Chawla et al. - 2019 - Bidirectional LSTM Autoencoder for Sequence Based .pdf:/Users/philmoremorrison/Zotero/storage/Y4WKXQTK/Chawla et al. - 2019 - Bidirectional LSTM Autoencoder for Sequence Based .pdf:application/pdf},
}
